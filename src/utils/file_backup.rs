use std::path::{Path, PathBuf};

use anyhow::{Context, Result};
use chrono::Utc;
use tokio::fs;
use tracing::{error, info, warn};

/// æ–‡ä»¶å¤‡ä»½ç®¡ç†å™¨
/// è´Ÿè´£ä¿å­˜ã€åˆ é™¤å’Œæ¢å¤æ–‡æ¡£çš„åŸå§‹æ–‡ä»¶å‰¯æœ¬
#[derive(Debug, Clone)]
pub struct FileBackup {
    backup_dir: PathBuf,
    /// å•ä¸ªæ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤ 10MB
    max_file_size: u64,
}

impl FileBackup {
    /// é»˜è®¤æœ€å¤§æ–‡ä»¶å¤§å°ï¼š10MB
    const DEFAULT_MAX_FILE_SIZE: u64 = 10 * 1024 * 1024;

    pub fn new<P: AsRef<Path>>(backup_dir: P) -> Self {
        Self {
            backup_dir: backup_dir.as_ref().to_path_buf(),
            max_file_size: Self::DEFAULT_MAX_FILE_SIZE,
        }
    }

    /// åˆ›å»ºå¸¦è‡ªå®šä¹‰é™åˆ¶çš„å¤‡ä»½ç®¡ç†å™¨
    pub fn with_limits<P: AsRef<Path>>(backup_dir: P, max_file_size: u64) -> Self {
        Self {
            backup_dir: backup_dir.as_ref().to_path_buf(),
            max_file_size,
        }
    }

    /// åˆå§‹åŒ–å¤‡ä»½ç›®å½•
    pub async fn init(&self) -> Result<()> {
        if !self.backup_dir.exists() {
            fs::create_dir_all(&self.backup_dir)
                .await
                .context("Failed to create backup directory")?;
            info!("ğŸ“ Created backup directory: {:?}", self.backup_dir);
        } else {
            info!("ğŸ“ Backup directory exists: {:?}", self.backup_dir);
        }
        Ok(())
    }

    /// ä¿å­˜æ–‡æ¡£å¤‡ä»½
    ///
    /// # Arguments
    /// * `doc_id` - æ–‡æ¡£ ID
    /// * `filename` - åŸå§‹æ–‡ä»¶å
    /// * `content` - æ–‡ä»¶å†…å®¹
    ///
    /// # Returns
    /// è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    pub async fn save_backup(
        &self, doc_id: &str, filename: &str, content: &str,
    ) -> Result<PathBuf> {
        // å®‰å…¨æ£€æŸ¥ 1: éªŒè¯ doc_idï¼ˆåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ï¼‰
        if !Self::is_safe_identifier(doc_id) {
            return Err(anyhow::anyhow!(
                "Invalid doc_id: contains unsafe characters"
            ));
        }

        // å®‰å…¨æ£€æŸ¥ 2: æ£€æŸ¥æ–‡ä»¶å¤§å°
        let content_size = content.len() as u64;
        if content_size > self.max_file_size {
            return Err(anyhow::anyhow!(
                "File size {} exceeds maximum allowed size {}",
                content_size,
                self.max_file_size
            ));
        }

        // ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        self.init().await?;

        let timestamp = Utc::now().format("%Y%m%d_%H%M%S");
        let safe_filename = self.sanitize_filename(filename);
        let backup_filename = format!("{}_{}_{}", doc_id, timestamp, safe_filename);

        // å®‰å…¨æ£€æŸ¥ 4: ç¡®ä¿è·¯å¾„åœ¨å¤‡ä»½ç›®å½•å†…
        let backup_path = self.backup_dir.join(&backup_filename);
        if !backup_path.starts_with(&self.backup_dir) {
            return Err(anyhow::anyhow!("Path traversal attempt detected"));
        }

        // ä¿å­˜æ–‡ä»¶
        fs::write(&backup_path, content)
            .await
            .context(format!("Failed to write backup file: {:?}", backup_path))?;

        info!(
            "ğŸ’¾ Saved backup: {} -> {:?} ({} bytes)",
            filename, backup_path, content_size
        );

        Ok(backup_path)
    }

    /// éªŒè¯æ ‡è¯†ç¬¦æ˜¯å¦å®‰å…¨ï¼ˆåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ï¼‰
    pub(crate) fn is_safe_identifier(s: &str) -> bool {
        if s.is_empty() || s.len() > 255 {
            return false;
        }
        s.chars()
            .all(|c| c.is_alphanumeric() || c == '_' || c == '-')
    }

    /// åˆ é™¤æ–‡æ¡£å¤‡ä»½
    ///
    /// # Arguments
    /// * `doc_id` - æ–‡æ¡£ ID
    ///
    /// # Returns
    /// è¿”å›åˆ é™¤çš„æ–‡ä»¶æ•°é‡
    pub async fn delete_backup(&self, doc_id: &str) -> Result<usize> {
        // å®‰å…¨æ£€æŸ¥: éªŒè¯ doc_id
        if !Self::is_safe_identifier(doc_id) {
            return Err(anyhow::anyhow!(
                "Invalid doc_id: contains unsafe characters"
            ));
        }

        let mut deleted_count = 0;

        // æ£€æŸ¥å¤‡ä»½ç›®å½•æ˜¯å¦å­˜åœ¨
        if !self.backup_dir.exists() {
            warn!("Backup directory does not exist: {:?}", self.backup_dir);
            return Ok(0);
        }

        // éå†å¤‡ä»½ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
        let mut entries = fs::read_dir(&self.backup_dir)
            .await
            .context("Failed to read backup directory")?;

        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();

            // å®‰å…¨æ£€æŸ¥: ç¡®ä¿è·¯å¾„åœ¨å¤‡ä»½ç›®å½•å†…
            if !path.starts_with(&self.backup_dir) {
                warn!("Skipping path outside backup directory: {:?}", path);
                continue;
            }

            // å®‰å…¨æ£€æŸ¥: åªå¤„ç†æ™®é€šæ–‡ä»¶ï¼Œè·³è¿‡ç¬¦å·é“¾æ¥
            if let Ok(metadata) = entry.metadata().await
                && !metadata.is_file()
            {
                continue;
            }

            if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {
                // æ£€æŸ¥æ–‡ä»¶åæ ¼å¼ï¼šå¿…é¡»ä»¥ "doc_id_" å¼€å¤´ï¼Œé¿å…è¯¯åˆ 
                let expected_prefix = format!("{}_", doc_id);
                if filename.starts_with(&expected_prefix) {
                    match fs::remove_file(&path).await {
                        Ok(_) => {
                            info!("ğŸ—‘ï¸  Deleted backup: {:?}", path);
                            deleted_count += 1;
                        },
                        Err(e) => {
                            error!("Failed to delete backup {:?}: {}", path, e);
                        },
                    }
                }
            }
        }

        if deleted_count == 0 {
            warn!("No backup files found for doc_id: {}", doc_id);
        }

        Ok(deleted_count)
    }

    /// è·å–æ–‡æ¡£çš„å¤‡ä»½æ–‡ä»¶è·¯å¾„
    ///
    /// # Arguments
    /// * `doc_id` - æ–‡æ¡£ ID
    ///
    /// # Returns
    /// è¿”å›æ‰€æœ‰åŒ¹é…çš„å¤‡ä»½æ–‡ä»¶è·¯å¾„
    pub async fn get_backup_paths(&self, doc_id: &str) -> Result<Vec<PathBuf>> {
        let mut backup_paths = Vec::new();

        if !self.backup_dir.exists() {
            return Ok(backup_paths);
        }

        let mut entries = fs::read_dir(&self.backup_dir)
            .await
            .context("Failed to read backup directory")?;

        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            if let Some(filename) = path.file_name().and_then(|n| n.to_str())
                && filename.starts_with(doc_id)
            {
                backup_paths.push(path);
            }
        }

        Ok(backup_paths)
    }

    /// è¯»å–å¤‡ä»½æ–‡ä»¶å†…å®¹
    ///
    /// # Arguments
    /// * `doc_id` - æ–‡æ¡£ ID
    ///
    /// # Returns
    /// è¿”å› (åŸå§‹æ–‡ä»¶å, å†…å®¹) å…ƒç»„
    pub async fn read_backup(&self, doc_id: &str) -> Result<Option<(String, String)>> {
        let backup_paths = self.get_backup_paths(doc_id).await?;

        if backup_paths.is_empty() {
            return Ok(None);
        }

        // å–æœ€æ–°çš„å¤‡ä»½ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼Œå› ä¸ºåŒ…å«æ—¶é—´æˆ³ï¼‰
        let latest_backup = backup_paths
            .iter()
            .max_by_key(|p| p.file_name())
            .context("Failed to find latest backup")?;

        let content = fs::read_to_string(latest_backup)
            .await
            .context(format!("Failed to read backup: {:?}", latest_backup))?;

        // ä»æ–‡ä»¶åä¸­æå–åŸå§‹æ–‡ä»¶å
        // æ ¼å¼: {doc_id}_{timestamp}_{original_filename}
        let filename = latest_backup
            .file_name()
            .and_then(|n| n.to_str())
            .and_then(|s| {
                // è·³è¿‡ doc_id å’Œ timestamp éƒ¨åˆ†
                let parts: Vec<&str> = s.splitn(3, '_').collect();
                parts.get(2).map(|s| s.to_string())
            })
            .unwrap_or_else(|| "unknown.txt".to_string());

        Ok(Some((filename, content)))
    }

    /// åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶
    ///
    /// # Returns
    /// è¿”å› (doc_id, æ–‡ä»¶å, å¤§å°, ä¿®æ”¹æ—¶é—´) åˆ—è¡¨
    pub async fn list_all_backups(
        &self,
    ) -> Result<Vec<(String, String, u64, chrono::DateTime<Utc>)>> {
        let mut backups = Vec::new();

        if !self.backup_dir.exists() {
            return Ok(backups);
        }

        let mut entries = fs::read_dir(&self.backup_dir)
            .await
            .context("Failed to read backup directory")?;

        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            if path.is_file()
                && let (Some(filename), Ok(metadata)) = (
                    path.file_name().and_then(|n| n.to_str()),
                    entry.metadata().await,
                )
            {
                // æå– doc_id (æ–‡ä»¶åç¬¬ä¸€éƒ¨åˆ†)
                let doc_id = filename.split('_').next().unwrap_or("unknown").to_string();

                let size = metadata.len();
                let modified = metadata
                    .modified()
                    .ok()
                    .and_then(|t| {
                        t.duration_since(std::time::UNIX_EPOCH)
                            .ok()
                            .and_then(|d| chrono::DateTime::from_timestamp(d.as_secs() as i64, 0))
                    })
                    .unwrap_or_else(Utc::now);

                backups.push((doc_id, filename.to_string(), size, modified));
            }
        }

        // æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        backups.sort_by(|a, b| b.3.cmp(&a.3));

        Ok(backups)
    }

    /// æ¸…ç†æ—§å¤‡ä»½
    /// æ¯ä¸ªæ–‡æ¡£åªä¿ç•™æœ€æ–°çš„ N ä¸ªå¤‡ä»½
    ///
    /// # Arguments
    /// * `keep_count` - æ¯ä¸ªæ–‡æ¡£ä¿ç•™çš„å¤‡ä»½æ•°é‡
    pub async fn cleanup_old_backups(&self, keep_count: usize) -> Result<usize> {
        use std::collections::HashMap;

        if !self.backup_dir.exists() {
            return Ok(0);
        }

        // æŒ‰ doc_id åˆ†ç»„æ‰€æœ‰å¤‡ä»½
        let mut doc_backups: HashMap<String, Vec<PathBuf>> = HashMap::new();

        let mut entries = fs::read_dir(&self.backup_dir)
            .await
            .context("Failed to read backup directory")?;

        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            if path.is_file()
                && let Some(filename) = path.file_name().and_then(|n| n.to_str())
            {
                let doc_id = filename.split('_').next().unwrap_or("unknown").to_string();
                doc_backups.entry(doc_id).or_default().push(path);
            }
        }

        let mut deleted_count = 0;

        // å¯¹æ¯ä¸ª doc_id çš„å¤‡ä»½è¿›è¡Œæ¸…ç†
        for (doc_id, mut paths) in doc_backups {
            if paths.len() <= keep_count {
                continue;
            }

            // æŒ‰æ–‡ä»¶åæ’åºï¼ˆæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼‰
            paths.sort_by(|a, b| b.file_name().cmp(&a.file_name()));

            // åˆ é™¤è¶…å‡ºä¿ç•™æ•°é‡çš„å¤‡ä»½
            for path in paths.iter().skip(keep_count) {
                match fs::remove_file(path).await {
                    Ok(_) => {
                        info!("ğŸ§¹ Cleaned up old backup: {:?}", path);
                        deleted_count += 1;
                    },
                    Err(e) => {
                        error!("Failed to delete old backup {:?}: {}", path, e);
                    },
                }
            }

            if deleted_count > 0 {
                info!(
                    "ğŸ§¹ Cleaned {} old backups for doc_id: {}",
                    deleted_count, doc_id
                );
            }
        }

        Ok(deleted_count)
    }

    /// æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨çš„å­—ç¬¦
    pub(crate) fn sanitize_filename(&self, filename: &str) -> String {
        let sanitized: String = filename
            .chars()
            .filter(|c| !c.is_control() && *c != '\u{0000}') // ç§»é™¤æ§åˆ¶å­—ç¬¦
            .map(|c| match c {
                // è·¯å¾„åˆ†éš”ç¬¦
                '/' | '\\' => '_',
                // Windows ä¿ç•™å­—ç¬¦
                ':' | '*' | '?' | '"' | '<' | '>' | '|' => '_',
                // ç‚¹å·å¼€å¤´ï¼ˆéšè—æ–‡ä»¶ï¼‰
                '.' => '_',
                // å…¶ä»–ä¸å®‰å…¨å­—ç¬¦
                '\0' | '\n' | '\r' => '_',
                _ => c,
            })
            .collect();

        // é™åˆ¶é•¿åº¦ï¼ˆæ–‡ä»¶åæœ€é•¿ 100 å­—ç¬¦ï¼‰
        let max_len = 100;
        if sanitized.len() > max_len {
            sanitized.chars().take(max_len).collect()
        } else if sanitized.is_empty() {
            "unnamed".to_string()
        } else {
            sanitized
        }
    }

    /// è·å–å¤‡ä»½ç›®å½•æ€»å¤§å°
    pub async fn get_total_size(&self) -> Result<u64> {
        let mut total_size = 0u64;

        if !self.backup_dir.exists() {
            return Ok(0);
        }

        let mut entries = fs::read_dir(&self.backup_dir)
            .await
            .context("Failed to read backup directory")?;

        while let Some(entry) = entries.next_entry().await? {
            if let Ok(metadata) = entry.metadata().await
                && metadata.is_file()
            {
                total_size += metadata.len();
            }
        }

        Ok(total_size)
    }
}
